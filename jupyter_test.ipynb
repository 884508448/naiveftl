{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25c86e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "from utils.ftl_data_loader import FTLDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54c38ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-25 19:52:04] ftl_data_loader.py:56 INFO - mapping label value 0 to -1, 1 to +1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.041827  0.037656  0.830468 ...  0.003406  0.139864  0.346127]\n",
      " [-0.072071 -0.215349 -0.12748  ...  0.134116 -0.078017 -0.203804]\n",
      " [-0.046688  0.135819  0.185993 ... -0.313597  0.861375 -0.955271]\n",
      " ...\n",
      " [ 0.002206 -0.220415 -0.12001  ... -0.149214 -0.405655  0.134179]\n",
      " [ 0.272182 -0.089065 -0.080786 ... -0.280846  0.243175 -0.598673]\n",
      " [-0.097331 -0.224257 -0.128853 ...  0.563206  0.56376  -0.494249]]\n"
     ]
    }
   ],
   "source": [
    "dt = FTLDataLoader(\"data/mini_nus_wide_train_guest.csv\")\n",
    "\n",
    "print(dt.data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba459f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.041827  0.037656  0.830468 ...  0.003406  0.139864  0.346127]\n",
      " [-0.072071 -0.215349 -0.12748  ...  0.134116 -0.078017 -0.203804]\n",
      " [-0.046688  0.135819  0.185993 ... -0.313597  0.861375 -0.955271]\n",
      " ...\n",
      " [ 0.002206 -0.220415 -0.12001  ... -0.149214 -0.405655  0.134179]\n",
      " [ 0.272182 -0.089065 -0.080786 ... -0.280846  0.243175 -0.598673]\n",
      " [-0.097331 -0.224257 -0.128853 ...  0.563206  0.56376  -0.494249]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(dt.data_matrix)\n",
    "print(type(dt.data_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffca21e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.182700e-02  3.765600e-02  8.304680e-01  2.136790e-01 -3.387810e-01\n",
      "  1.019740e-01 -1.041850e-01 -1.894880e-01 -1.984440e-01 -6.569690e-01\n",
      " -1.541440e-01  2.354200e-01  2.624260e-01  1.662290e-01 -3.545120e-01\n",
      "  3.365400e-02  5.879100e-02 -2.722110e-01 -9.506200e-02  5.550700e-02\n",
      " -2.923020e-01  3.888200e-02  2.910600e-01 -4.537150e-01  3.779600e-02\n",
      "  1.080530e-01  7.204300e-02 -2.666550e-01 -6.825200e-02  7.766600e-02\n",
      " -3.086940e-01  6.125900e-02  3.182200e-01 -4.290860e-01  2.327750e-01\n",
      " -1.500920e-01  5.670000e-02 -1.615550e-01 -3.128110e-01 -1.176400e-02\n",
      " -1.200530e-01  1.733760e-01  3.195960e-01 -4.933110e-01  1.501580e-01\n",
      " -2.484840e-01  1.032060e-01 -1.220880e-01  2.446900e-02 -3.989850e-01\n",
      " -2.169190e-01  2.145850e-01  2.080830e-01 -3.583770e-01  1.017000e-01\n",
      " -1.666290e-01 -2.410620e-01 -2.174440e-01 -9.039100e-02 -7.249780e-01\n",
      " -1.810880e-01  1.994820e-01  2.621480e-01 -3.551010e-01  4.335700e-02\n",
      "  7.815600e-02 -2.467940e-01 -6.329300e-02 -1.468860e-01  8.507400e-02\n",
      " -2.565730e-01  2.642800e-02  2.922990e-01 -3.989600e-01  3.034730e-01\n",
      "  1.086330e-01 -2.636060e-01 -1.654000e-01  1.866600e-02 -1.204050e-01\n",
      " -2.479680e-01  2.066690e-01  3.445360e-01 -5.256960e-01  2.387610e-01\n",
      "  9.433000e-03 -1.109600e-01 -3.687300e-01 -1.308180e-01 -2.046180e-01\n",
      " -6.401800e-02  2.134720e-01  3.214880e-01 -5.088490e-01  2.097430e-01\n",
      " -2.577660e-01 -1.892800e-01 -1.337000e-03 -4.585760e-01 -2.371910e-01\n",
      "  2.355430e-01 -7.268100e-02  2.203930e-01 -3.779350e-01  1.789280e-01\n",
      " -1.559720e-01 -1.845220e-01 -4.533800e-02 -6.664890e-01 -1.349740e-01\n",
      "  2.899480e-01  2.520820e-01  9.962000e-03  1.026140e-01 -3.598230e-01\n",
      "  3.951200e-02  3.982300e-02 -2.954700e-02 -4.293310e-01 -4.223500e-02\n",
      " -1.821260e-01 -5.438800e-02  2.410030e-01 -2.898380e-01 -1.684000e-03\n",
      "  3.295330e-01 -1.551130e-01  8.181500e-02 -3.840730e-01 -1.862010e-01\n",
      " -9.724000e-03  2.694840e-01  3.067960e-01 -3.901130e-01  2.010290e-01\n",
      " -1.043060e-01 -7.658400e-02  2.241300e-02 -2.068000e-03 -2.510270e-01\n",
      "  1.230300e-02  2.192490e-01  3.218920e-01 -4.088500e-01  2.322900e-02\n",
      " -6.266000e-02  3.535500e-02 -1.451550e-01  3.676300e-02 -2.897640e-01\n",
      " -1.378130e-01 -6.169000e-03  1.889870e-01 -1.799800e-01 -6.755000e-03\n",
      " -1.506510e-01 -1.619590e-01  1.523500e-02 -5.921600e-02 -6.583050e-01\n",
      "  5.091600e-02  2.646900e-01  2.500200e-01 -3.520160e-01  9.797000e-03\n",
      " -6.911200e-02 -1.315000e-03 -3.121960e-01 -1.362250e-01 -1.084910e-01\n",
      " -1.730480e-01 -4.497000e-03  1.687170e-01 -1.705310e-01 -7.820400e-02\n",
      " -1.928070e-01 -2.417000e-03  3.461000e-02 -4.073530e-01  9.867000e-02\n",
      "  1.920540e-01 -1.383300e-01  7.531000e-03 -3.090170e-01  2.018380e-01\n",
      " -2.973220e-01 -2.219990e-01 -5.372000e-02 -1.005114e+00 -1.673140e-01\n",
      " -1.034360e-01  2.381090e-01  5.719900e-02 -2.438310e-01  2.222810e-01\n",
      " -2.220020e-01 -1.887530e-01 -2.149500e-02 -9.376550e-01 -6.538900e-02\n",
      "  2.980510e-01  1.238400e-02 -1.363500e-02 -2.662660e-01  1.974780e-01\n",
      " -3.018890e-01 -5.778500e-02  7.364200e-02 -1.030627e+00 -8.251600e-02\n",
      "  3.307930e-01 -5.178790e-01 -1.192600e-02 -1.946000e-03  1.141030e-01\n",
      "  8.560880e-01  4.208920e-01  3.216430e-01 -4.621120e-01 -7.013140e-01\n",
      "  5.749720e-01  1.100870e-01 -3.340670e-01 -1.152300e-01 -3.724800e-02\n",
      " -2.255270e-01  5.115050e-01  6.658690e-01 -3.278070e-01  7.227000e-02\n",
      " -3.557240e-01 -2.814180e-01 -2.222660e-01 -1.729600e-01 -2.942620e-01\n",
      "  1.133200e-02 -1.610840e-01 -1.932760e-01 -9.423700e-02  6.684600e-02\n",
      " -1.293800e-01 -1.095150e-01 -6.375400e-02  5.705770e-01 -2.750390e-01\n",
      "  8.085720e-01 -2.487190e-01 -1.490340e-01 -1.808690e-01 -1.049720e-01\n",
      " -8.260900e-02 -5.369700e-02 -6.506190e-01 -2.673340e-01 -5.297300e-02\n",
      "  9.908600e-01  2.793540e-01 -1.211630e-01  6.600100e-02 -3.647410e-01\n",
      " -5.528810e-01  6.634620e-01 -3.950000e-02 -2.642050e-01 -1.791570e-01\n",
      "  5.502040e-01  8.030440e-01 -2.591530e-01  1.869300e-02  4.937000e-02\n",
      " -2.673600e-01 -2.077440e-01 -1.724260e-01 -1.333890e-01 -2.300480e-01\n",
      " -1.210750e-01 -1.568330e-01 -7.215900e-02 -9.795800e-02 -1.485410e-01\n",
      " -9.352600e-02  1.941900e-02 -4.778300e-02  6.344710e-01 -2.241510e-01\n",
      "  9.122310e-01 -1.224840e-01 -9.776800e-02 -7.740600e-02 -5.989500e-02\n",
      "  8.773300e-02 -4.145100e-02 -4.508640e-01 -2.738720e-01 -5.086800e-02\n",
      "  1.056706e+00  2.335150e-01 -1.151200e-02 -3.276490e-01 -5.040190e-01\n",
      "  7.478340e-01 -1.130810e-01 -3.576600e-02 -2.369630e-01 -1.594950e-01\n",
      "  5.763750e-01  8.935310e-01 -2.335440e-01 -3.289000e-03 -2.414190e-01\n",
      " -1.824520e-01 -1.544530e-01 -1.575570e-01 -1.171440e-01 -2.092590e-01\n",
      " -1.067590e-01 -1.430160e-01 -6.354800e-02 -1.081200e-01 -8.051400e-02\n",
      " -7.220200e-02 -4.109700e-02  6.619790e-01 -1.320980e-01 -2.042780e-01\n",
      "  9.695610e-01 -1.114110e-01 -6.799200e-02 -6.747000e-02 -5.210300e-02\n",
      " -3.643600e-02 -5.457950e-01 -2.564650e-01 -9.022700e-02 -1.687550e-01\n",
      " -1.504580e-01  1.089781e+00  2.057170e-01 -7.615000e-02 -3.053530e-01\n",
      " -4.517180e-01  8.075080e-01 -2.035700e-02 -2.200770e-01 -1.470440e-01\n",
      "  5.982520e-01  8.709460e-01  9.628750e-01 -2.178310e-01 -8.780500e-02\n",
      " -2.255390e-01 -1.672420e-01 -1.437690e-01 -1.069900e-01 -1.965040e-01\n",
      " -9.822900e-02 -1.344090e-01 -1.479080e-01 -5.834400e-02 -8.878700e-02\n",
      " -7.291400e-02 -6.586900e-02 -3.698000e-02  6.852310e-01 -1.916910e-01\n",
      "  1.003062e+00 -1.043430e-01 -1.015910e-01  5.877300e-02 -6.148700e-02\n",
      " -4.751400e-02 -3.326600e-02 -1.034930e-01 -2.007480e-01 -4.663610e-01\n",
      "  3.674560e-01 -1.190620e-01 -1.259170e-01  1.055435e+00  3.148400e-02\n",
      "  5.521570e-01  4.847720e-01  3.700500e-02  6.614110e-01 -1.915700e-02\n",
      "  9.833390e-01  1.266699e+00  1.151154e+00  6.294080e-01  5.202580e-01\n",
      "  6.125500e-02 -1.526110e-01 -5.405200e-02  1.327580e-01 -2.559100e-01\n",
      "  1.946140e-01  2.484990e-01  8.132970e-01 -3.256020e-01  5.116490e-01\n",
      "  8.520000e-04  6.349900e-02  5.619560e-01  2.223790e-01  7.379910e-01\n",
      "  3.706700e-01 -1.187820e-01  3.555800e-01 -4.542230e-01  2.487340e-01\n",
      " -1.226440e-01 -1.564400e-01 -9.651200e-02 -4.253110e-01 -4.564350e-01\n",
      " -4.649820e-01 -2.697150e-01  6.643400e-02  7.412000e-02 -9.965900e-02\n",
      " -8.722800e-02 -1.289830e-01 -1.271490e-01  2.430000e-03 -3.094550e-01\n",
      " -1.619800e-01 -6.442070e-01 -5.079680e-01 -2.495870e-01 -4.482170e-01\n",
      " -3.051560e-01 -2.880520e-01 -4.510390e-01 -3.706510e-01 -5.737800e-02\n",
      "  9.709800e-02 -3.284160e-01 -4.732780e-01 -3.029860e-01  3.965970e-01\n",
      " -4.338080e-01 -1.197010e-01  4.305180e-01 -2.731570e-01  6.870600e-02\n",
      "  1.656430e-01 -9.908500e-02  7.545800e-02  5.602060e-01  1.408790e-01\n",
      "  3.491000e-02  4.113000e-03  5.449450e-01  9.435200e-02  3.910400e-02\n",
      " -3.701480e-01 -5.425780e-01  7.246110e-01 -4.050780e-01 -5.025520e-01\n",
      " -3.495890e-01 -4.386280e-01  1.852970e-01  6.392200e-02 -3.922920e-01\n",
      " -6.083730e-01 -4.467940e-01 -5.045490e-01 -2.084390e-01 -3.741220e-01\n",
      " -5.007370e-01  2.724750e-01  1.040590e-01 -4.150130e-01 -6.380440e-01\n",
      " -5.340610e-01 -6.477990e-01 -4.272950e-01 -5.293480e-01 -6.481800e-02\n",
      "  2.626630e-01  1.776460e-01 -3.969090e-01 -5.986600e-01 -4.385370e-01\n",
      " -5.483020e-01 -3.740190e-01 -4.699950e-01  3.107060e-01  1.994810e-01\n",
      " -1.077200e-01 -4.155540e-01 -6.686100e-01 -4.811730e-01 -5.379780e-01\n",
      " -3.981220e-01 -5.398230e-01 -4.100550e-01 -5.682890e-01 -3.892980e-01\n",
      " -6.034000e-01 -1.255200e-02 -3.735270e-01 -4.759200e-01 -3.844450e-01\n",
      " -4.882460e-01 -4.616290e-01 -5.292470e-01 -3.934630e-01 -4.433050e-01\n",
      " -4.610660e-01 -5.562090e-01  1.403850e-01 -3.905220e-01 -4.815180e-01\n",
      "  3.577270e-01  2.292100e-01 -4.226100e-01 -6.625360e-01 -5.609230e-01\n",
      " -6.695970e-01 -4.478070e-01 -5.517890e-01  3.712700e-02 -3.957860e-01\n",
      " -5.694490e-01 -4.252120e-01 -6.462150e-01 -3.928870e-01 -5.927270e-01\n",
      " -4.152480e-01 -5.853800e-01 -4.740660e-01 -5.319440e-01 -1.687070e-01\n",
      " -4.206670e-01 -4.892170e-01 -5.095430e-01 -3.953250e-01 -4.319290e-01\n",
      " -4.701430e-01 -3.664260e-01 -4.744760e-01 -4.035140e-01 -5.341880e-01\n",
      "  2.597230e-01 -3.699740e-01 -5.354920e-01 -4.090710e-01 -5.503770e-01\n",
      " -3.828030e-01 -5.494940e-01 -3.774400e-01 -5.233610e-01 -3.716500e-01\n",
      " -5.513170e-01 -9.531600e-02  5.050100e-02 -4.012780e-01 -5.499320e-01\n",
      " -3.439160e-01 -4.294830e-01 -3.883310e-01 -4.680070e-01 -3.574360e-01\n",
      " -4.851730e-01 -3.913280e-01 -5.338380e-01 -1.046200e-02 -4.403130e-01\n",
      " -4.514710e-01 -4.301030e-01 -5.018860e-01 -4.724070e-01 -5.249670e-01\n",
      " -4.416330e-01 -4.844730e-01 -3.953580e-01 -4.863660e-01 -1.644770e-01\n",
      " -3.762350e-01 -3.413060e-01 -4.002380e-01 -4.493920e-01 -4.205560e-01\n",
      " -4.151580e-01 -4.788170e-01 -5.342490e-01 -4.462290e-01 -5.865730e-01\n",
      " -2.002700e-02 -4.630310e-01 -3.962580e-01 -4.135980e-01 -4.278020e-01\n",
      "  2.525680e-01 -3.572170e-01  7.209500e-02  8.272300e-02 -2.559820e-01\n",
      " -1.035040e-01 -1.803800e-02  9.312800e-02 -2.660520e-01  1.159550e-01\n",
      "  2.630810e-01 -4.052620e-01  4.519500e-02  1.285040e-01 -2.507130e-01\n",
      " -1.656150e-01  1.257450e-01  6.567680e-01 -2.873940e-01  4.239300e-02\n",
      "  2.598250e-01 -4.625830e-01  4.536600e-02  1.907710e-01 -2.730700e-01\n",
      " -1.854320e-01  2.236290e-01 -2.905260e-01 -2.610350e-01  2.784800e-02\n",
      "  2.448550e-01 -3.014930e-01  2.021710e-01  8.926800e-02 -3.112200e-02\n",
      " -2.776000e-02  3.406000e-03  1.398640e-01  3.461270e-01]\n",
      "634\n"
     ]
    }
   ],
   "source": [
    "y=dt.data_matrix[0]\n",
    "print(y)\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87bb9d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "model.add_module(\"layer 1\",nn.Linear(in_features=634,out_features=32,dtype=torch.float32))\n",
    "# model.add_module(\"layer 1 activation\",nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e119f3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out=model(torch.tensor(y,dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5747d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4814, 0.4261, 0.4621, 0.5383, 0.5205, 0.5507, 0.4562, 0.4756, 0.4527,\n",
      "        0.5699, 0.5592, 0.5479, 0.4877, 0.5218, 0.5013, 0.5485, 0.4855, 0.5035,\n",
      "        0.5196, 0.4757, 0.5161, 0.4746, 0.4290, 0.5287, 0.5347, 0.4121, 0.4602,\n",
      "        0.5216, 0.5147, 0.5733, 0.5378, 0.4913], grad_fn=<SigmoidBackward0>)\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "print(out)\n",
    "print(len(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9bd072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "model.add_module(\"layer 1\",nn.Linear(in_features=634,out_features=32,dtype=torch.float32))\n",
    "# model.add_module(\"layer 1 activation\",nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c67b359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3174,  0.2573,  0.2001,  0.2104,  0.1491,  0.2742, -0.1522,  0.3750,\n",
      "        -0.3093, -0.0495,  0.1455,  0.0136,  0.0608, -0.0341,  0.0972, -0.0113,\n",
      "         0.2052,  0.1338, -0.0390, -0.1311, -0.1478,  0.0685, -0.1044, -0.2133,\n",
      "         0.2327, -0.2503, -0.0035, -0.0706,  0.3198,  0.0988,  0.2309,  0.0808],\n",
      "       grad_fn=<AddBackward0>)\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "out=model(torch.tensor(y,dtype=torch.float32))\n",
    "print(out)\n",
    "print(len(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1d41c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors=torch.tensor(dt.data_matrix,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64c509a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0418,  0.0377,  0.8305,  ...,  0.0034,  0.1399,  0.3461],\n",
      "        [-0.0721, -0.2153, -0.1275,  ...,  0.1341, -0.0780, -0.2038],\n",
      "        [-0.0467,  0.1358,  0.1860,  ..., -0.3136,  0.8614, -0.9553],\n",
      "        ...,\n",
      "        [ 0.0022, -0.2204, -0.1200,  ..., -0.1492, -0.4057,  0.1342],\n",
      "        [ 0.2722, -0.0891, -0.0808,  ..., -0.2808,  0.2432, -0.5987],\n",
      "        [-0.0973, -0.2243, -0.1289,  ...,  0.5632,  0.5638, -0.4942]])\n"
     ]
    }
   ],
   "source": [
    "print(tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1563b408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6207, 0.5464, 0.4837, 0.4784, 0.5271, 0.4710, 0.5397, 0.5185, 0.6477,\n",
      "         0.4201, 0.5848, 0.4700, 0.4826, 0.4340, 0.5468, 0.4222, 0.4310, 0.4648,\n",
      "         0.4592, 0.4400, 0.4062, 0.4840, 0.4870, 0.6160, 0.5484, 0.4565, 0.5208,\n",
      "         0.4208, 0.5032, 0.5927, 0.5479, 0.5287],\n",
      "        [0.4613, 0.5230, 0.5358, 0.4737, 0.5199, 0.5336, 0.4843, 0.5290, 0.5167,\n",
      "         0.4984, 0.4702, 0.4993, 0.5584, 0.5385, 0.5244, 0.5718, 0.4961, 0.5059,\n",
      "         0.4900, 0.5588, 0.4968, 0.5623, 0.4678, 0.4785, 0.4735, 0.5086, 0.5519,\n",
      "         0.4643, 0.5335, 0.5121, 0.4931, 0.4913],\n",
      "        [0.4470, 0.5165, 0.4759, 0.4706, 0.4673, 0.5351, 0.5484, 0.5798, 0.4792,\n",
      "         0.4883, 0.4713, 0.5137, 0.4294, 0.4786, 0.5104, 0.4766, 0.4335, 0.5370,\n",
      "         0.4039, 0.5283, 0.5536, 0.5590, 0.4881, 0.5690, 0.4955, 0.4496, 0.4933,\n",
      "         0.5416, 0.4336, 0.5084, 0.4430, 0.5242],\n",
      "        [0.5803, 0.5535, 0.5227, 0.5111, 0.5482, 0.5118, 0.5166, 0.4385, 0.5424,\n",
      "         0.4188, 0.4476, 0.4702, 0.5101, 0.5084, 0.5753, 0.4992, 0.5192, 0.5261,\n",
      "         0.5506, 0.5156, 0.4585, 0.5419, 0.4478, 0.4849, 0.5649, 0.4640, 0.5193,\n",
      "         0.5121, 0.4491, 0.5543, 0.5081, 0.5525],\n",
      "        [0.5603, 0.5513, 0.5075, 0.5101, 0.4827, 0.4675, 0.4587, 0.5177, 0.4799,\n",
      "         0.4879, 0.5316, 0.4927, 0.4630, 0.4806, 0.5376, 0.4370, 0.4563, 0.4565,\n",
      "         0.4863, 0.5370, 0.4610, 0.4927, 0.4834, 0.4894, 0.5306, 0.5285, 0.5167,\n",
      "         0.4962, 0.4472, 0.4796, 0.4640, 0.4991],\n",
      "        [0.5440, 0.4969, 0.5248, 0.5643, 0.4782, 0.4802, 0.4793, 0.4502, 0.5037,\n",
      "         0.4049, 0.5623, 0.5305, 0.4408, 0.4573, 0.4961, 0.5232, 0.5740, 0.4840,\n",
      "         0.4875, 0.4932, 0.5857, 0.5324, 0.4405, 0.5157, 0.5062, 0.4712, 0.4892,\n",
      "         0.4898, 0.4674, 0.4452, 0.4461, 0.5064],\n",
      "        [0.5132, 0.5218, 0.4844, 0.5243, 0.4664, 0.4499, 0.5726, 0.4057, 0.6115,\n",
      "         0.5750, 0.4534, 0.4288, 0.5802, 0.5740, 0.5080, 0.4409, 0.4228, 0.5058,\n",
      "         0.4958, 0.4811, 0.4814, 0.4853, 0.5397, 0.5211, 0.5608, 0.5412, 0.4471,\n",
      "         0.4969, 0.4964, 0.4877, 0.5751, 0.4883],\n",
      "        [0.5677, 0.4728, 0.5480, 0.5060, 0.5684, 0.5770, 0.5357, 0.4481, 0.4472,\n",
      "         0.4567, 0.5327, 0.4608, 0.4685, 0.5360, 0.4562, 0.4594, 0.5554, 0.5151,\n",
      "         0.4180, 0.5888, 0.5594, 0.5171, 0.5311, 0.5596, 0.5001, 0.4631, 0.5533,\n",
      "         0.5222, 0.4885, 0.5988, 0.4940, 0.4661],\n",
      "        [0.4807, 0.5221, 0.5210, 0.4827, 0.4741, 0.5049, 0.5189, 0.5160, 0.4750,\n",
      "         0.5496, 0.5042, 0.4995, 0.5058, 0.4917, 0.5421, 0.5197, 0.5019, 0.5135,\n",
      "         0.4713, 0.5037, 0.4458, 0.5712, 0.4788, 0.4785, 0.5198, 0.4679, 0.4512,\n",
      "         0.4491, 0.4944, 0.4820, 0.5317, 0.5097],\n",
      "        [0.5322, 0.5367, 0.4562, 0.5018, 0.4705, 0.4831, 0.5266, 0.5020, 0.5583,\n",
      "         0.5729, 0.4907, 0.4898, 0.5398, 0.4941, 0.5170, 0.4881, 0.5364, 0.5153,\n",
      "         0.5045, 0.4507, 0.4615, 0.5141, 0.5917, 0.5233, 0.5837, 0.4555, 0.5034,\n",
      "         0.4654, 0.4806, 0.4684, 0.4791, 0.5395],\n",
      "        [0.5058, 0.5210, 0.4519, 0.4781, 0.5277, 0.4735, 0.4846, 0.5156, 0.5047,\n",
      "         0.4948, 0.5176, 0.4646, 0.5396, 0.5242, 0.5115, 0.4686, 0.4781, 0.4350,\n",
      "         0.4892, 0.4574, 0.5249, 0.4444, 0.4975, 0.5197, 0.4424, 0.5109, 0.5125,\n",
      "         0.5242, 0.4942, 0.4161, 0.4959, 0.5018],\n",
      "        [0.4871, 0.4944, 0.5495, 0.5437, 0.4738, 0.4656, 0.5041, 0.4941, 0.5143,\n",
      "         0.5098, 0.5204, 0.5079, 0.5129, 0.4797, 0.4962, 0.4562, 0.4382, 0.4227,\n",
      "         0.5055, 0.5039, 0.4802, 0.5142, 0.4705, 0.5394, 0.5063, 0.5274, 0.5252,\n",
      "         0.5044, 0.4802, 0.4876, 0.5283, 0.4724],\n",
      "        [0.4396, 0.4970, 0.5269, 0.4830, 0.4220, 0.5110, 0.4754, 0.4821, 0.4372,\n",
      "         0.5001, 0.4620, 0.4945, 0.4922, 0.5081, 0.4877, 0.4620, 0.4770, 0.4301,\n",
      "         0.4589, 0.5247, 0.4641, 0.5821, 0.4610, 0.5029, 0.4909, 0.5475, 0.5503,\n",
      "         0.5251, 0.4648, 0.4582, 0.5411, 0.4619],\n",
      "        [0.5127, 0.5054, 0.4536, 0.4590, 0.5104, 0.4585, 0.5549, 0.5608, 0.5312,\n",
      "         0.5080, 0.5437, 0.5002, 0.5603, 0.5403, 0.4939, 0.4051, 0.4027, 0.5349,\n",
      "         0.5151, 0.4714, 0.4105, 0.5020, 0.4850, 0.5198, 0.5118, 0.4949, 0.4949,\n",
      "         0.4621, 0.4975, 0.4664, 0.5391, 0.5050],\n",
      "        [0.5856, 0.5309, 0.4503, 0.5837, 0.5428, 0.4600, 0.5104, 0.4399, 0.4932,\n",
      "         0.4868, 0.5092, 0.3837, 0.4825, 0.5605, 0.5097, 0.4879, 0.4634, 0.4187,\n",
      "         0.5174, 0.4368, 0.3976, 0.5502, 0.5586, 0.5110, 0.4163, 0.5017, 0.4982,\n",
      "         0.4821, 0.4648, 0.6751, 0.5751, 0.5720],\n",
      "        [0.4652, 0.5438, 0.5137, 0.4829, 0.5393, 0.5003, 0.5456, 0.5529, 0.5965,\n",
      "         0.5418, 0.4434, 0.4458, 0.4709, 0.4708, 0.5586, 0.4906, 0.5220, 0.5197,\n",
      "         0.4487, 0.4687, 0.4926, 0.6009, 0.4830, 0.5250, 0.4999, 0.4762, 0.4486,\n",
      "         0.4772, 0.4865, 0.5336, 0.5241, 0.4892],\n",
      "        [0.5667, 0.6019, 0.5006, 0.4936, 0.5461, 0.5108, 0.4798, 0.5122, 0.4880,\n",
      "         0.4928, 0.5100, 0.4962, 0.5763, 0.5130, 0.5499, 0.5359, 0.4469, 0.5182,\n",
      "         0.5369, 0.5056, 0.4310, 0.5302, 0.5276, 0.5494, 0.5515, 0.5260, 0.5251,\n",
      "         0.4856, 0.4854, 0.4844, 0.5012, 0.5368],\n",
      "        [0.5528, 0.4891, 0.4401, 0.5175, 0.5499, 0.5064, 0.5129, 0.5679, 0.4753,\n",
      "         0.4942, 0.4966, 0.4652, 0.4493, 0.5047, 0.5502, 0.5365, 0.5707, 0.5749,\n",
      "         0.5274, 0.4600, 0.5086, 0.4999, 0.4939, 0.4794, 0.5668, 0.5412, 0.4812,\n",
      "         0.4525, 0.5153, 0.5314, 0.4894, 0.4857],\n",
      "        [0.3618, 0.3807, 0.4642, 0.4750, 0.5564, 0.5944, 0.4609, 0.4285, 0.4462,\n",
      "         0.4477, 0.3705, 0.6022, 0.4191, 0.5060, 0.4329, 0.5985, 0.6445, 0.6596,\n",
      "         0.3525, 0.4733, 0.5371, 0.5463, 0.5649, 0.3923, 0.4458, 0.4264, 0.3995,\n",
      "         0.4734, 0.5228, 0.5301, 0.4729, 0.5866]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential()\n",
    "model.add_module(\"layer 1\",nn.Linear(in_features=634,out_features=32,dtype=torch.float32))\n",
    "model.add_module(\"layer 1 activation\",nn.Sigmoid())\n",
    "outs=model(tensors)\n",
    "print(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5814dda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6207, 0.5464, 0.4837, 0.4784, 0.5271, 0.4710, 0.5397, 0.5185, 0.6477,\n",
      "        0.4201, 0.5848, 0.4700, 0.4826, 0.4340, 0.5468, 0.4222, 0.4310, 0.4648,\n",
      "        0.4592, 0.4400, 0.4062, 0.4840, 0.4870, 0.6160, 0.5484, 0.4565, 0.5208,\n",
      "        0.4208, 0.5032, 0.5927, 0.5479, 0.5287], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(outs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db5398e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1  1  1 -1  1  1  1 -1  1  1 -1  1 -1  1  1 -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "y=dt.labels\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9962b9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34e1ae63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.81785682, 1.66926715, 1.46632695, 1.62892944, 1.44457519,\n",
       "       1.41125774, 1.76030144, 1.20707241, 1.89512911, 1.37179124,\n",
       "       1.52785546, 1.08930635, 1.39137992, 1.49156198, 1.5499925 ,\n",
       "       1.15804708, 1.45555213, 1.165373  , 1.34882885, 1.37160242,\n",
       "       1.61421636, 1.59274638, 1.55431834, 1.92141977, 1.50303733,\n",
       "       1.31645605, 1.59025815, 1.66952842, 1.25275144, 1.76506597,\n",
       "       1.60993922, 1.54380757])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.dot(y,outs.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b973efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5331, 0.4131, 0.4842, 0.4922, 0.4480, 0.5122, 0.5235, 0.4771, 0.5209,\n",
      "         0.5281, 0.5350, 0.4777, 0.5115, 0.5011, 0.4891, 0.5058, 0.4827, 0.5885,\n",
      "         0.4648, 0.5143, 0.5296, 0.4674, 0.5262, 0.6198, 0.4879, 0.5467, 0.4363,\n",
      "         0.4125, 0.4672, 0.4550, 0.5230, 0.6268],\n",
      "        [0.5230, 0.5304, 0.5803, 0.5269, 0.4930, 0.4536, 0.4809, 0.5073, 0.4940,\n",
      "         0.5131, 0.5107, 0.5188, 0.4911, 0.4846, 0.4525, 0.4864, 0.5489, 0.5303,\n",
      "         0.4991, 0.4890, 0.5365, 0.4875, 0.5283, 0.4749, 0.5192, 0.4710, 0.5846,\n",
      "         0.5672, 0.5134, 0.6162, 0.5755, 0.5261],\n",
      "        [0.4836, 0.4294, 0.4770, 0.4689, 0.4563, 0.4207, 0.4873, 0.5636, 0.5211,\n",
      "         0.4805, 0.5083, 0.4517, 0.4649, 0.5048, 0.4604, 0.4950, 0.4927, 0.5607,\n",
      "         0.5137, 0.4450, 0.4828, 0.4798, 0.5425, 0.4960, 0.4368, 0.4817, 0.4866,\n",
      "         0.4046, 0.4675, 0.4700, 0.4660, 0.4562],\n",
      "        [0.4671, 0.4894, 0.4680, 0.5388, 0.5121, 0.6052, 0.5223, 0.5727, 0.4923,\n",
      "         0.4126, 0.5007, 0.5534, 0.6016, 0.5179, 0.4953, 0.4684, 0.3924, 0.4821,\n",
      "         0.5230, 0.5819, 0.5572, 0.4446, 0.4969, 0.4438, 0.5174, 0.4846, 0.4647,\n",
      "         0.4659, 0.5485, 0.4912, 0.5060, 0.5910],\n",
      "        [0.5539, 0.5318, 0.4295, 0.5209, 0.5040, 0.4709, 0.5233, 0.5316, 0.4918,\n",
      "         0.5555, 0.5374, 0.4950, 0.5214, 0.4897, 0.4924, 0.4529, 0.5364, 0.4867,\n",
      "         0.5495, 0.5121, 0.4607, 0.5244, 0.4672, 0.4975, 0.5042, 0.5492, 0.4755,\n",
      "         0.4879, 0.4978, 0.5286, 0.5370, 0.5408]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4235, 0.4342, 0.5325, 0.5362, 0.5606, 0.5311, 0.4713, 0.5218, 0.4468,\n",
      "         0.4862, 0.4846, 0.4452, 0.4991, 0.4828, 0.5121, 0.4849, 0.5229, 0.5080,\n",
      "         0.5278, 0.4794, 0.4966, 0.4564, 0.5050, 0.4458, 0.4634, 0.5054, 0.4894,\n",
      "         0.5074, 0.5153, 0.4803, 0.5602, 0.5043],\n",
      "        [0.4978, 0.4804, 0.4529, 0.5038, 0.4785, 0.4859, 0.4852, 0.5139, 0.4749,\n",
      "         0.4464, 0.4925, 0.4593, 0.5313, 0.5568, 0.4726, 0.4328, 0.4782, 0.5932,\n",
      "         0.5259, 0.4519, 0.4679, 0.5705, 0.5220, 0.5806, 0.5508, 0.4957, 0.4060,\n",
      "         0.3728, 0.4524, 0.5140, 0.4943, 0.5494],\n",
      "        [0.4159, 0.5128, 0.5513, 0.4378, 0.5214, 0.4499, 0.4781, 0.4982, 0.4999,\n",
      "         0.5294, 0.4630, 0.4843, 0.5426, 0.5316, 0.3901, 0.5071, 0.5680, 0.5123,\n",
      "         0.5134, 0.4809, 0.5150, 0.4340, 0.4425, 0.4610, 0.4738, 0.5594, 0.5573,\n",
      "         0.5552, 0.4913, 0.4818, 0.4355, 0.4329],\n",
      "        [0.5221, 0.4886, 0.5031, 0.5632, 0.4956, 0.5184, 0.4776, 0.5240, 0.5042,\n",
      "         0.5093, 0.4547, 0.5350, 0.5186, 0.4694, 0.4871, 0.4708, 0.4796, 0.4620,\n",
      "         0.4556, 0.5305, 0.4915, 0.5338, 0.5007, 0.5575, 0.4835, 0.4737, 0.4699,\n",
      "         0.4799, 0.5182, 0.5183, 0.5784, 0.5637]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential()\n",
    "model.add_module(\"layer 1\",nn.Linear(in_features=634,out_features=32,dtype=torch.float32))\n",
    "model.add_module(\"layer 1 activation\",nn.Sigmoid())\n",
    "outs1=model(tensors[0:5])\n",
    "outs2=model(tensors[5:9])\n",
    "print(outs1)\n",
    "print(outs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62972c6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m outs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mouts1\n\u001b[1;32m      3\u001b[0m outs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mouts2\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mouts\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not list"
     ]
    }
   ],
   "source": [
    "outs=[]\n",
    "outs+=outs1\n",
    "outs+=outs2\n",
    "print(outs[[1,2,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ca8b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
